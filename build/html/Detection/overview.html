<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Overview &mdash; giiads_platform  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Data Handling and Preparation" href="Data%20Processing/user.html" />
    <link rel="prev" title="Prediction" href="../Classification/predict.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            giiads_platform
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tabular_data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Tabular_data/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tabular_data/Preprocessing/user.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tabular_data/ml/user.html">Machine Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Classification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Classification/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Classification/dataimportation.html">Data Handling and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Classification/Model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Classification/predict.html">Prediction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Detection</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#intro">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#import">Importation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#imagehandle">Image Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#annotation">Annotation Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="#augment">Data Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#export">Data Exportation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id9">Model Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id11">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id13">Model Exportation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Data%20Processing/user.html">Data Handling and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="_models/user.html">Model</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">giiads_platform</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Detection/overview.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h1>
<p><strong>Table of Contents:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="#intro">Introduction</a></p></li>
<li><p><a class="reference external" href="#import">Importation</a></p></li>
<li><p><a class="reference external" href="#imageHandle">Image Handling</a></p></li>
<li><p><a class="reference external" href="#annotation">Annotation Tool</a></p></li>
<li><p><a class="reference external" href="#augment">Data Augmentation</a></p></li>
<li><p><a class="reference external" href="#export">Data Exportation</a></p></li>
<li><p><a class="reference external" href="#model_selection">Model Selection</a></p></li>
<li><p><a class="reference external" href="#model_training">Model Training</a></p></li>
<li><p><a class="reference external" href="#model_evaluation">Model Evaluation</a></p></li>
<li><p><a class="reference external" href="#model_exportation">Model Exportation</a></p></li>
</ul>
<section id="intro">
<span id="id1"></span><h2>Introduction<a class="headerlink" href="#intro" title="Link to this heading"></a></h2>
<p>Introducing the Object Detection functionality, a tool designed for efficient object detection workflows. Users can easily import both local and external data in various formats, ensuring compatibility with diverse datasets. The app’s advanced cleaning features help maintain dataset accuracy, while its intuitive labeling system facilitates precise object categorization. With built-in preprocessing options like data splitting and augmentation, the Object Detection App optimizes datasets for improved model training. The app also generates detailed reports on data quality, providing valuable insights for users. With a user-friendly interface, the Object Detection App simplifies the object detection process, making it an essential tool for streamlined data management.</p>
</section>
<section id="import">
<span id="id2"></span><h2>Importation<a class="headerlink" href="#import" title="Link to this heading"></a></h2>
<p>Introducing the Object Detection App, a versatile tool designed to streamline object detection workflows. This application excels in simplifying the importation process, allowing users to seamlessly bring in data from both local and external sources. Supporting a variety of file formats, the Object Detection App ensures compatibility with diverse datasets, providing a hassle-free experience for users. Whether it’s local data stored on your device or external data from different repositories</p>
</section>
<section id="imagehandle">
<span id="id3"></span><h2>Image Handling<a class="headerlink" href="#imagehandle" title="Link to this heading"></a></h2>
<p>Within the Object Detection App, the image handling feature facilitates a seamless workflow for object detection tasks. Users can effortlessly transform and annotate images with bounding boxes, ensuring precision in their analyses. The functionality allows for extracting essential information from input data, visualizing bounding boxes on images, and displaying transformed images with overlays. This feature enhances the clarity of object detection results and provides a user-friendly interface for efficiently evaluating annotated datasets.</p>
</section>
<section id="annotation">
<span id="id4"></span><h2>Annotation Tool<a class="headerlink" href="#annotation" title="Link to this heading"></a></h2>
<p>The Object Detection App comes equipped with a user-friendly annotation tool designed to streamline the process of labeling objects within images. This intuitive tool enables users to efficiently mark and annotate objects of interest, contributing to the creation of labeled datasets for training object detection models. With a simple and accessible interface, users can easily draw bounding boxes around objects, assign labels, and fine-tune annotations as needed. The annotation tool supports precision in object localization, ensuring that the labeled datasets accurately reflect the objects present in the images. This feature simplifies the often intricate task of annotation, making it accessible to users with varying levels of expertise in object detection. The annotation tool is an essential component for generating high-quality labeled datasets, laying the foundation for robust and accurate model training within the Object Detection App.</p>
</section>
<section id="augment">
<span id="id5"></span><h2>Data Augmentation<a class="headerlink" href="#augment" title="Link to this heading"></a></h2>
<p>The Object Detection App incorporates a dynamic augmentation feature to enrich and diversify your datasets. This functionality seamlessly applies specified augmentations to images and bounding boxes, ensuring enhanced dataset variability. Through this feature, users can effortlessly generate augmented versions of their images, preserving bounding box annotations for accurate object detection. The augmented files can be conveniently retrieved for further analysis, fostering flexibility in model training. This augmentation capability contributes to improved model robustness, enabling more accurate and reliable object detection across diverse scenarios and conditions.</p>
</section>
<section id="export">
<span id="id6"></span><h2>Data Exportation<a class="headerlink" href="#export" title="Link to this heading"></a></h2>
<p>The Object Detection App simplifies data exportation with a dedicated feature designed to efficiently manage paired image and label data. The Exporter class seamlessly handles the process of exporting data to a local directory, providing a convenient way to organize and store your datasets. Users can utilize the split_data method to partition paired data into training, validation, and test sets, streamlining the preparation for model training and evaluation. With the export_local method, exporting paired data to a local directory becomes a straightforward task, ensuring accessibility and ease of use. The default_handling method further enhances the data export process, providing users with a standardized approach for efficient handling. This data exportation feature is integral to maintaining a well-organized and accessible dataset for successful object detection workflows.</p>
</section>
<section id="id7">
<span id="id8"></span><h2>Model Selection<a class="headerlink" href="#id7" title="Link to this heading"></a></h2>
<p>The Object Detection App offers a variety of models for object detection. Users can choose from:</p>
<ol class="arabic simple">
<li><p>YOLOv8: A popular object detection model.</p></li>
<li><p>TensorFlow Model Zoo: A collection of pre-trained object detection models provided by TensorFlow.</p></li>
<li><p>Custom Model: Users can construct their own object detection model based on YOLO configuration.</p></li>
</ol>
</section>
<section id="id9">
<span id="id10"></span><h2>Model Training<a class="headerlink" href="#id9" title="Link to this heading"></a></h2>
<p>Once a model is selected, users can proceed to train it using the platform’s comprehensive training feature. This includes the ability to choose hyperparameters for the training process, providing a tailored approach to model training.</p>
</section>
<section id="id11">
<span id="id12"></span><h2>Model Evaluation<a class="headerlink" href="#id11" title="Link to this heading"></a></h2>
<p>After training, the platform facilitates model evaluation. Users can test the trained model on an image, a video, or a webcam, providing a practical way to assess the model’s performance.</p>
</section>
<section id="id13">
<span id="id14"></span><h2>Model Exportation<a class="headerlink" href="#id13" title="Link to this heading"></a></h2>
<p>Finally, the trained model can be exported for deployment or further use. The platform supports various export formats, accommodating different deployment environments and requirements.</p>
<p>Each model option comes with its own set of features and capabilities, providing users with the flexibility to choose the object detection model that best suits their needs. Whether they prefer YOLOv8, a model from the TensorFlow Model Zoo, or a custom model, they can easily train and deploy their chosen model using the platform’s features.</p>
<p>For detailed instructions on using each model option, refer to the respective documentation sections. This feature simplifies the often complex task of model selection and training, making it accessible to users with varying levels of expertise in object detection. The model selection and training feature is an essential component for generating high-quality object detection models, laying the foundation for robust and accurate model training within the Object Detection App..</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../Classification/predict.html" class="btn btn-neutral float-left" title="Prediction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Data%20Processing/user.html" class="btn btn-neutral float-right" title="Data Handling and Preparation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Chorouk Malmoum.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>