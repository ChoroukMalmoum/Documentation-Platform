<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model &mdash; giiads_platform  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="Data Handling and Preparation" href="../Data%20Processing/user.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            giiads_platform
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tabular_data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Tabular_data/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Tabular_data/Preprocessing/user.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Tabular_data/ml/user.html">Machine Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Classification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/dataimportation.html">Data Importation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/Model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Classification/predict.html">Prediction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Detection</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Data%20Processing/user.html">Data Handling and Preparation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#yolov8">YOLOv8</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-model-zoo">TensorFlow Model Zoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-model">Custom Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">giiads_platform</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/Detection/_models/user.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="model">
<span id="model-selection"></span><h1>Model<a class="headerlink" href="#model" title="Link to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>The Model section of the platform allows users to choose the model they want to train for object detection and train it on their <a class="reference external" href="../Data Processing/user.html">own data</a>. They have the following options:</p>
<ol class="arabic simple">
<li><p>YOLOv8: A popular object detection model.</p></li>
<li><p>TensorFlow Model Zoo: A collection of pre-trained object detection models provided by TensorFlow.</p></li>
<li><p>Custom Model: Users can construct their own object detection model based on YOLO configuration.</p></li>
</ol>
</section>
<section id="yolov8">
<h2>YOLOv8<a class="headerlink" href="#yolov8" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://docs.ultralytics.com/">YOLOv8</a>, the latest offering from <a class="reference external" href="https://www.ultralytics.com/">Ultralytics</a>, is a top-tier model that builds upon the YOLO (You Only Look Once) architecture to enhance the capabilities of its predecessors.
It introduces innovative features that improve performance, flexibility, and efficiency, and supports a wide range of vision AI tasks, including detection, segmentation, pose estimation, tracking, and classification.
Thanks to its versatility, YOLOv8 serves as a valuable tool for various applications.</p>
<p>Users can use YOLOv8 directly from the platform to train it on their own dataset.
The platform provides a simple interface that allows you to easily configure the model parameters and train the model using the provided dataset.
See the <a href="#id4"><span class="problematic" id="id5">`Tutorial`_</span></a> for more details on how to train YOLOv8 on the platform.</p>
<p>For those preferring a code-based approach, the <a class="reference external" href="yolov8/yolov8model.html">YoloModel</a> class provides a way to harness the power of YOLOv8.
This class offers a straightforward API to configure model parameters and train it on your dataset.
It also facilitates inference using the trained model and model export.</p>
<p>The class includes the following key methods:</p>
<ul class="simple">
<li><p><a class="reference external" href="yolov8/trainyolov8.html">train</a>: Trains the model on the dataset and can resume training from a checkpoint.</p></li>
<li><p><a class="reference external" href="yolov8/predict_on_image.html">predict_on_image</a>: Performs inference on a single image.</p></li>
<li><p><a class="reference external" href="yolov8/predict_on_video.html">predict_on_video</a>: Executes inference on a video.</p></li>
<li><p><a class="reference external" href="yolov8/exportyolov8.html">export</a>: Exports the trained model.</p></li>
</ul>
</section>
<section id="tensorflow-model-zoo">
<h2>TensorFlow Model Zoo<a class="headerlink" href="#tensorflow-model-zoo" title="Link to this heading"></a></h2>
<p>The <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">TensorFlow Model Zoo</a> is a collection of pre-trained object detection models that can be used for various tasks.
These models, trained on the comprehensive COCO 2017 dataset, are ready for immediate inference tasks, especially if users categories of interest align with those in the COCO dataset.</p>
<p>However, the real power of these models is unleashed when they are used as a starting point for training on their own unique datasets. Our platform allows you to select one of these pre-trained models, initialize it with the pre-trained weights, and then train it on their dataset. This can potentially improve the model’s performance and reduce training time.</p>
<p>To directly use a model from the TensorFlow Model Zoo for training on your own dataset, see the <a href="#id6"><span class="problematic" id="id7">`Tutorial`_</span></a> for detailed instructions.</p>
<p>The <a class="reference external" href="Tensorflow/tfmodels.html">TensorflowModels</a> class provides a code-based approach to using these models. This class allows you to easily configure the model parameters and train it on your dataset. It also facilitates inference using the trained model and model export.</p>
<p>The class includes the following key methods:</p>
<ul>
<li><p><a class="reference external" href="Tensorflow/download_model.html">download_model</a>: Downloads the model from the TensorFlow Model Zoo if url is provided.</p></li>
<li><dl>
<dt><a class="reference external" href="Tensorflow/labelmap.html">create_label_map</a>: Creates a label map for the dataset.</dt><dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>A label map is a text file that maps each of the used labels to an integer value. This file is used to map the labels to indices, which are then used to construct the ground truth and prediction tensors.</p>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><a class="reference external" href="Tensorflow/tfrecords.html">data_to_tfrecord</a>: Converts the dataset to <a class="reference external" href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TFRecord format</a>.</dt><dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>TFRecord is the format required by TensorFlow Object Detection API for training.</p>
</div>
</dd>
</dl>
</li>
<li><p><a class="reference external" href="Tensorflow/modeltype.html">get_model_type</a>: Returns the model type based on the configuration of the model. This can be used to modify the configuration of the model.</p></li>
<li><p><cite>update_config_basic &lt;TensorFlow/config.html&gt;_</cite>: Updates the configuration of the model based on the provided parameters.</p></li>
<li><p><a class="reference external" href="Tensorflow/train.html">train</a>: Trains the model on the dataset.</p></li>
<li><p><a class="reference external" href="Tensorflow/eval.html">evaluate</a>: Evaluates the model’s performance on the dataset.</p></li>
</ul>
<p>In order to test the model, we provide two functions that can be used to perform inference on images and webcam videos:</p>
<ul class="simple">
<li><p><a class="reference external" href="Tensorflow/testimage.html">test_model_on_image</a>: Performs inference on a single image.</p></li>
<li><p><a class="reference external" href="Tensorflow/testvideo.html">test_model_on_camera</a>: Executes inference on a webcam.</p></li>
</ul>
</section>
<section id="custom-model">
<h2>Custom Model<a class="headerlink" href="#custom-model" title="Link to this heading"></a></h2>
<p>Our platform empowers users to construct their own object detection models, leveraging the <a class="reference external" href="https://arxiv.org/abs/1506.02640">YOLO (You Only Look Once)</a> configuration as a foundation. This provides users with the flexibility to customize the model architecture and training process according to their specific requirements.</p>
<p>The platform assists users in creating their models by allowing them to add layers (such as convolutional layers, max pooling layers, etc.) and choose options as per their needs. It also validates the architecture to ensure that the created model has the potential to perform effectively.</p>
<p>To directly construct a custom model from the platform, follow the instructions in the <a href="#id8"><span class="problematic" id="id9">`Tutorial`_</span></a>.</p>
<p>The <a class="reference external" href="Custom/model.html">CustomYoloModel</a> class allows users to create their own object detection model. This class includes the following methods:</p>
<ul class="simple">
<li><p><a class="reference external" href="Custom/add_conv.html">add_conv_layer</a>: This method allows users to add a convolutional layer to the architecture with the specified parameters (kernel size, number of output channnels, stride, padding).</p></li>
<li><p><a class="reference external" href="Custom/add_max.html">add_maxpool_layer</a>: This method allows users to add a max pooling layer to the architecture.</p></li>
<li><p><a class="reference external" href="Custom/add_dense.html">add_dense_block</a>: This method adds a dense block to the architecture. A dense block consists of two convolutional layers that are repeated a certain number of times.</p></li>
<li><p><a class="reference external" href="Custom/remove_last.html">remove_last_layer</a>: This method removes the last layer from the architecture.</p></li>
<li><p><a class="reference external" href="Custom/remove_last_n_layers.html">remove_last_n_layers</a>: This method removes the last n layers from the architecture.</p></li>
<li><p><a class="reference external" href="Custom/remove_all.html">remove_all_layers</a>: This method removes all layers from the architecture.</p></li>
<li><p><a class="reference external" href="Custom/modify.html">modify_layer</a>: This method modifies the specified layer in the architecture.</p></li>
<li><p><a class="reference external" href="Custom/conv_before_max.html">add_conv_layer_before_maxpool</a>: This method adds a convolutional layer before a max pooling layer in the architecture.</p></li>
<li><p><a class="reference external" href="Custom/validate.html">validate_architecture</a>: This method validates the model architecture to ensure it is potentially effective.</p></li>
</ul>
<p>The <a class="reference external" href="Custom/train.html">train_Custom_model</a> function can be used to train the model once the chosen architecture is validated. This function takes care of the entire training process, including loading the data, setting up the training loop, and saving the trained model.</p>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading"></a></h2>
<p>The user model section of the platform provides users with the flexibility to choose the object detection model that best suits their needs. Whether they prefer YOLOv8, a model from the TensorFlow Model Zoo, or a custom model, they can easily train and deploy their chosen model using the platform’s features.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For detailed instructions on using each model option, refer to the respective documentation sections.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../Data%20Processing/user.html" class="btn btn-neutral float-left" title="Data Handling and Preparation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Chorouk Malmoum.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>